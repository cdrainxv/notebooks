{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWK: A Csse Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Monday, April 23, I went to the first phase of an interview (and hopefully not the last) to be a Junior Programmer Analyst. The company seems to be the ideal opportunity for someone just starting out in the software development field, which I extrapolated from their job ad:\n",
    "    \n",
    "    * A university degree or a diploma in an applied field;\n",
    "    * Familiarity with the following: JavaScript, HTML, CSS, Python, and SQL;\n",
    "    * Familiarity with database design; and\n",
    "    * Familiarity with Unix.\n",
    "    * Successful candidates will have a passion for computing science. \n",
    "    * Candidates who do not have a strong desire to improve their programming skills need not apply. \n",
    "    * Junior Programmers will receive internal training â€“ frequent code reviews by Senior Programmers, iterative quality of code feedback and direction for improvement, problem- solving meeting participation, and self-directed or classroom courses as required. \n",
    "    \n",
    "These are all the markings of a great learning environment that fosters continuous improvement from senior developers and code reviews. I felt that I met a majority of what they were looking for and applied forthwith hoping against all hope just for a chance for an inteview.\n",
    "\n",
    "\n",
    "I was told that the initial inteview phase would consist of a programming case study that last an hour. I tried to eke out any clue as to what it entailed, but to no avail, being that there isn't much preperation one could do outside of just showing up. It turned out to be quite true as whence I arrived I was presented a computer and 7 questions to answer using [**awk**](https://www.gnu.org/software/gawk/manual/gawk.html). I had tested awk once before several months ago, but at the time I was just playing around with it and didn't commit anything to memory. I believe I would have failed handsomely were it not for the fact that I could make use of the provided and any online sources. As I was pressed for time and my mind was running amok, I opted to just make use of the internet and sites like stackoverflow. I've had open book examinations before, however in all those instances I was familiar with the material and/or the provided resources (usually a book) that I was calm, cool, and collected during the entirety of the exam. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWK Basics\n",
    "\n",
    "I don't want to cover the entirety of the awk system, mainly because the manual would accomplish that task better, but I also want highlight some of the awk commands I used in the case study. In the case study I only got through 4 out of the 7 questions within the hour. I am not too disappointed in that fact, however the answers I provided felt hollow because I wasn't too sure of what I was inputting. Some of the commands were foreign to me, especially some of the builtin variables like **NF**, **NR**, **\\$0**, **\\$1**, **BEGIN**, **END**, etc, although I could take a gander at them, I would rather be certain. Therefore after I got home I set to learn the basics of AWK, focusing on the very commands I used in the case study. I can now fully see the benefits of knowing a program like awk as I could use it in place of **pandas** to explore files.\n",
    "\n",
    "\n",
    "Here's some of the basics using some example files. Near the end I will use these very commands to re-answer some of the case study questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: **%%bash** is a magic command to load the bash shell in Jupyter. All commands can be written in a shell environment or in a textfile and run in the shell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builtin Variables\n",
    "\n",
    "AWK reads in a file and splits it into **records** and **fields**. Records default to newlines (\"\\n\") meaning each line is a record. Fields are how lines are seperated, defaulting to whitespace.\n",
    "\n",
    "The record number (NR) and field number (NF) can be displayed in the output if desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 The grand old Duke of York 6\n",
      "2 He had ten thousand men 5\n",
      "3 He marched them up to the top of the hill 10\n",
      "4 And he marched them down again 6\n",
      "5 And when they were up they were up 8\n",
      "6 And when they were down they were down 8\n",
      "7 And when they were only half-way up 7\n",
      "8 They were neither up nor down 6\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# NR at the beginning of each line, NF at the end of each line\n",
    "# 8 lines --> 8 records\n",
    "# For the first line --> 6 fields (the field separator is whitespace)\n",
    "awk '{ print NR, $0, NF }' dukeofyork.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use builtins such as **\\$0**, **\\$1**, etc to return specific fields from each record. As shown above $0 returns ___all___ the fields. In fact we can state the ordering of which they should be displayed. In the **names.txt** file, the order is firstnames preceded by surnames. Let's display it  as \"surname, firstname\" fashion. We can add the \", \" as a separator by concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GallowayGretchen\n",
      "SteeleIsaac\n",
      "MyersWayne\n",
      "LeeLillith\n",
      "BlackwellMolly\n",
      "ArnoldMaia\n",
      "ReeseLev\n",
      "GuthrieCarlos\n",
      "BuckSophia\n",
      "MitchellVincent\n",
      "HarrisBuffy\n",
      "MilesReuben\n",
      "FowlerBrendan\n",
      "HancockMason\n",
      "BooneNigel\n",
      "ForemanGretchen\n",
      "GoodmanSerena\n",
      "VelezShoshana\n",
      "HughesEve\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Notice the second field ($2) is first, and the firest field ($1) is second.\n",
    "# The names are concatenated\n",
    "awk '{ print $2 $1 }' names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galloway, Gretchen\n",
      "Steele, Isaac\n",
      "Myers, Wayne\n",
      "Lee, Lillith\n",
      "Blackwell, Molly\n",
      "Arnold, Maia\n",
      "Reese, Lev\n",
      "Guthrie, Carlos\n",
      "Buck, Sophia\n",
      "Mitchell, Vincent\n",
      "Harris, Buffy\n",
      "Miles, Reuben\n",
      "Fowler, Brendan\n",
      "Hancock, Mason\n",
      "Boone, Nigel\n",
      "Foreman, Gretchen\n",
      "Goodman, Serena\n",
      "Velez, Shoshana\n",
      "Hughes, Eve\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# To add a space between the first and surnames we have two options\n",
    "# awk '{print $2, $1}' names.txt\n",
    "# or \n",
    "# awk '{print $2 \" \" $1}' names.txt\n",
    "#\n",
    "# However we want to separate the names by way of a comma\n",
    "awk '{ print $2 \", \" $1 }' names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not limited to just seperating our output using spaces and commas, we have the options for other characters such as \"\\t\", \"\\n\", etc. Just as we can be specific with which fields we want to retrieve, likewise, we can specify the recods we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They were neither up nor down\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# NR==8 focuses on only the 8th line\n",
    "awk 'NR==8 { print $0 }' dukeofyork.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10 He marched them up to the top of the hill\n",
      "5 8 And when they were up they were up\n",
      "6 8 And when they were down they were down\n",
      "8 6 They were neither up nor down\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk 'NR==8 || NF>=8 { print NR, NF, $0 }' dukeofyork.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above ouput we use comparison operators to output the lines of text where the record number was either 8 or the number of fields werre 8 or greater. Since awk is both a program and language it comes instilled with very similar operators and conditionals present in C and a majority of ther languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Structures\n",
    "\n",
    "awk has control structures such as if/else statements for branching and for loops for ... looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short line:  The grand old Duke of York 6\n",
      "Short line:  He had ten thousand men 5\n",
      "Long line:  He marched them up to the top of the hill 10\n",
      "Short line:  And he marched them down again 6\n",
      "Long line:  And when they were up they were up 8\n",
      "Long line:  And when they were down they were down 8\n",
      "Long line:  And when they were only half-way up 7\n",
      "Short line:  They were neither up nor down 6\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '\n",
    "    {\n",
    "        if (NF <= 6) {\n",
    "            print \"Short line: \", $0, NF\n",
    "        } else {\n",
    "            print \"Long line: \", $0, NF\n",
    "        }\n",
    "    }\n",
    "' dukeofyork.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the nice formatting, indentation, spacing, et al. The job ad mentioned adherence to **clean code**, of which formatting is a tenet. In a majority of my code I wrote in the case study I didn't follow that tenent closely opting for completion and foolishly thinking I could come back and format it later. It's justifiable to think that I might have lost some points there. Also of consideration is that as your code starts to span more than one line as above, it would be wise to move it to a file, with **awk** as the commonly used extension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > for_ex.awk\n",
    "{\n",
    "    for ( i = 1; i <= 2; i++ ) {\n",
    "        print \"Line \" NR \", field \" i \": \" $i;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1, field 1: The\n",
      "Line 1, field 2: grand\n",
      "Line 2, field 1: He\n",
      "Line 2, field 2: had\n",
      "Line 3, field 1: He\n",
      "Line 3, field 2: marched\n",
      "Line 4, field 1: And\n",
      "Line 4, field 2: he\n",
      "Line 5, field 1: And\n",
      "Line 5, field 2: when\n",
      "Line 6, field 1: And\n",
      "Line 6, field 2: when\n",
      "Line 7, field 1: And\n",
      "Line 7, field 2: when\n",
      "Line 8, field 1: They\n",
      "Line 8, field 2: were\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# -f flag denotes that there is an awk program file to be read from\n",
    "# prints the first two fields in each line. \n",
    "awk -f for_ex.awk dukeofyork.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex\n",
    "\n",
    "The AWK program requires a command/action and/or a pattern. The above examples have focused on the commamnds thus far, especially the common usely **print** command. We can also use a regex pattern to either filter our data to exact a command upon or to search for specific patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wayne Myers\n",
      "Molly Blackwell\n",
      "Maia Arnold\n",
      "Vincent Mitchell\n",
      "Reuben Miles\n",
      "Mason Hancock\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '/M/ { print $0 }' names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To limit our search to specific fields we use the **~** to match or **!~** to not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molly Blackwell\n",
      "Maia Arnold\n",
      "Mason Hancock\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '$1 ~ /M/ { print $0 }' names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gretchen Galloway\n",
      "Molly Blackwell\n",
      "Vincent Mitchell\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# print names of people with surnames 8 letters or longer\n",
    "awk '$2 ~ /.{8,}/ { print $0 }' names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gretchen Galloway\n",
      "Vincent Mitchell\n",
      "Reuben Miles\n",
      "Brendan Fowler\n",
      "Gretchen Foreman\n",
      "Serena Goodman\n",
      "He had ten thousand men\n",
      "And when they were up they were up\n",
      "And when they were down they were down\n",
      "And when they were only half-way up\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '/en/ { print $0 }' names.txt dukeofyork.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is of great import that that I mention that multiple files can be used for awk's input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overwriting Defaults\n",
    "\n",
    "As mentioned earlier, awk has some built in defaults which we can also modify. All the files we have worked with are broken up by whitespace (FS) and newlines (RS), but this won't be the case with all the files we will ever work with or on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player,team,pos,number\r",
      "\r\n",
      "K. Durant,GS Warriors,SF,35\r",
      "\r\n",
      "J. Harden,Houston Rockets,SG,13\r",
      "\r\n",
      "K.A Towns,Minnesota Timberwolves,C,32\r",
      "\r\n",
      "Kyrie Irving,Boston Celtics,PG,11\r",
      "\r\n",
      "Anthony Davis,NO Pelicans,PF,23\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "cat nba_players.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our nba_players.csv file's \"fields\" are separated by commas - at least that's what we want, or else awk might resort to it's default and render this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 player,team,pos,number\r\n",
      "3 K. Durant,GS Warriors,SF,35\r\n",
      "3 J. Harden,Houston Rockets,SG,13\r\n",
      "3 K.A Towns,Minnesota Timberwolves,C,32\r\n",
      "3 Kyrie Irving,Boston Celtics,PG,11\r\n",
      "3 Anthony Davis,NO Pelicans,PF,23\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '{ print NF, $0 }' nba_players.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice \"player,team,pos,number\" is considered ___one___ field, not the four desired, with the rest of fields in the other records having misleading fields numbers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 player,team,pos,number\r\n",
      "4 K. Durant,GS Warriors,SF,35\r\n",
      "4 J. Harden,Houston Rockets,SG,13\r\n",
      "4 K.A Towns,Minnesota Timberwolves,C,32\r\n",
      "4 Kyrie Irving,Boston Celtics,PG,11\r\n",
      "4 Anthony Davis,NO Pelicans,PF,23\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# -F allows us to input our own field separator, in this case it's \",\"\n",
    "awk -F , '{ print NF, $0 }' nba_players.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Gretchen G|llow|y\n",
      "3 Is||c Steele\n",
      "2 W|yne Myers|\n",
      "1 Lillith Lee||\n",
      "2 Molly Bl|ckwell|\n",
      "3 M|i| Arnold\n",
      "1 Lev Reese||\n",
      "2 C|rlos Guthrie|\n",
      "2 Sophi| Buck|\n",
      "1 Vincent Mitchell||\n",
      "2 Buffy H|rris|\n",
      "1 Reuben Miles||\n",
      "2 Brend|n Fowler|\n",
      "3 M|son H|ncock\n",
      "1 Nigel Boone||\n",
      "2 Gretchen Forem|n|\n",
      "3 Seren| Goodm|n\n",
      "3 Shosh|n| Velez\n",
      "1 Eve Hughes||\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# We can use any character or even a pattern for the FS\n",
    "# The FS has been replace with '|' to highlight where the fields separate\n",
    "awk -F a '{ print NF, $1 \"|\" $2 \"|\" $3 }' names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGIN & END\n",
    "\n",
    "BEGIN allows us to setup variables, modify defaults, etc before any action is taken upon any input file(s). \n",
    "END can be used to reformat how our data is outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player,team,pos,number\r\n",
      "K. Durant,GS Warriors,SF,35\r\n",
      "J. Harden,Houston Rockets,SG,13\r\n",
      "K.A Towns,Minnesota Timberwolves,C,32\r\n",
      "Kyrie Irving,Boston Celtics,PG,11\r\n",
      "Anthony Davis,NO Pelicans,PF,23\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Here we set our FS to be \",\". No need for -F flag\n",
    "awk 'BEGIN{FS=\",\"} { print $ 0}' nba_players.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 player team pos number\r\n",
      "4 K. Durant GS Warriors SF 35\r\n",
      "4 J. Harden Houston Rockets SG 13\r\n",
      "4 K.A Towns Minnesota Timberwolves C 32\r\n",
      "4 Kyrie Irving Boston Celtics PG 11\r\n",
      "4 Anthony Davis NO Pelicans PF 23\r\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "awk 'BEGIN{FS=\",\"} { print NF, $1, $2, $3, $4 }' nba_players.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything now is tab separated, but if we want it be be separated nicely we have to make use of the **printf** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player\tteam\tpos\tnumber\r\n",
      "K. Durant\tGS Warriors\tSF\t35\r\n",
      "J. Harden\tHouston Rockets\tSG\t13\r\n",
      "K.A Towns\tMinnesota Timberwolves\tC\t32\r\n",
      "Kyrie Irving\tBoston Celtics\tPG\t11\r\n",
      "Anthony Davis\tNO Pelicans\tPF\t23\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk 'BEGIN{FS=\",\"} { printf(\"%s\\t%s\\t%s\\t%s\\n\", $1, $2, $3, $4) }' nba_players.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every column is lined up, but not under the correct heading as the fields have a lot of characters that bleed over to the following columns. We need to add some padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player          team                     pos  number\r\n",
      "K. Durant       GS Warriors              SF   35\r\n",
      "J. Harden       Houston Rockets          SG   13\r\n",
      "K.A Towns       Minnesota Timberwolves   C    32\r\n",
      "Kyrie Irving    Boston Celtics           PG   11\r\n",
      "Anthony Davis   NO Pelicans              PF   23\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk 'BEGIN{FS=\",\"} { printf(\"%-15s %-24s %-4s %s\\n\", $1, $2, $3, $4) }' nba_players.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed the \"\\t\" character and opted for adding a width character that pads any unused space with whitespace. For ex. \"%-15s\" **left-aligns** the column and gives it a width of 15 characters, padding any leftover width with whitespace.\n",
    "\n",
    "I want to save this nicely formatted, columnar data as a **tsv** (tab separated values) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "awk 'BEGIN{FS=\",\"} { printf(\"%-15s %-24s %-4s %s\\n\", $1, $2, $3, $4) }' nba_players.csv > nba_players.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player          team                     pos  number\r",
      "\r\n",
      "K. Durant       GS Warriors              SF   35\r",
      "\r\n",
      "J. Harden       Houston Rockets          SG   13\r",
      "\r\n",
      "K.A Towns       Minnesota Timberwolves   C    32\r",
      "\r\n",
      "Kyrie Irving    Boston Celtics           PG   11\r",
      "\r\n",
      "Anthony Davis   NO Pelicans              PF   23\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "cat nba_players.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study Questions\n",
    "\n",
    "I don't have the exact test files used, but I can create similar ones. The first type of file just consisted of low integers, mainly 1, 0, -1. Something akin to this:\n",
    "\n",
    "\n",
    "\n",
    "The second type had integers intersperesed with string characters, quite similar to this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > test1.txt\n",
    "1  -1 1 0\n",
    "1  1  0 0\n",
    "-1 -1 1 1\n",
    "-1 0  0 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -1 1 0\n",
      "1  1  0 0\n",
      "-1 -1 1 1\n",
      "-1 0  0 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat test1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Return Coordinates Of Invalid Values (Negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 1 Column: 2 Value: -1\n",
      "Line: 3 Column: 1 Value: -1\n",
      "Line: 3 Column: 2 Value: -1\n",
      "Line: 4 Column: 1 Value: -1\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "awk '\n",
    "    {\n",
    "        for ( i = 1; i <= 4; i++ ) {\n",
    "            if ( $i < 0 ) {\n",
    "                print \"Line:\", NR, \"Column:\", i, \"Value:\", $i\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "' test1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -1 1 0\n",
      "1  1  0 0\n",
      "-1 -1 1 1\n",
      "-1 0  0 1\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cat test1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Change All Invalid Numbers To 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 1 0\n",
      "1  1  0 0\n",
      "0 0 1 1\n",
      "0 0 0 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '\n",
    "    {\n",
    "        for ( i = 1; i <= NF; i++ ) {\n",
    "            if ( $i < 0 ) {\n",
    "                $i = sub(/$i/, 0)\n",
    "            }\n",
    "        }\n",
    "        print $0\n",
    "    }\n",
    "' test1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Sum All Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: 1 sum: 0\n",
      "column: 2 sum: -1\n",
      "column: 3 sum: 2\n",
      "column: 4 sum: 2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '\n",
    "    {\n",
    "            for ( i = 1; i <= NF; i++ ) {\n",
    "                sum[i] += $i\n",
    "            }\n",
    "    }\n",
    "    \n",
    "    END {\n",
    "            for ( i = 1; i <= NR; i++ ) {\n",
    "                print \"column:\", i, \"sum:\", sum[i]\n",
    "            }\n",
    "    }\n",
    "' test1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  -1 1 0\r\n",
      "1  1  0 0\r\n",
      "-1 -1 1 1\r\n",
      "-1 0  0 1\r\n"
     ]
    }
   ],
   "source": [
    "cat test1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Count Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 4\n",
      "0 5\n",
      "1 7\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk '\n",
    "    { \n",
    "            for ( i = 1; i <= NF; i++ ) {\n",
    "                arr[$i]++\n",
    "            }\n",
    "    } \n",
    "    END { \n",
    "            for (n in arr)  {\n",
    "                print n, arr[n] \n",
    "            }\n",
    "    }\n",
    "' test1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's where we'll leave this overview for now. A lot of information has been brushed over and left to be investigated on own's one, including user-defined functions, additional builtins, commandline flags, etc. In the following posts and even in the wild, I'll attempt to use awk more often."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
